<?xml version="1.0"?>
<!-- A sample job config for sketching the k8s use case with shared fs -->
<job_conf>
  <plugins>
    <plugin id="local" type="runner" load="galaxy.jobs.runners.local:LocalJobRunner" workers="4"/>
    <plugin id="k8s" type="runner" load="galaxy.jobs.runners.kubernetes:KubernetesJobRunner">
      <param id="k8s_use_service_account" from_environ="GALAXY_RUNNERS_K8S_USE_SERVICE_ACCOUNT">true</param>
      <param id="k8s_persistent_volume_claim_name" from_environ="GALAXY_RUNNERS_K8S_PERSISTENT_VOLUME_CLAIM_NAME">galaxy-pvc</param>
      <!-- The following mount path needs to be the initial part of the "file_path" and "new_file_path" paths
            set in universe_wsgi.ini (or equivalent general galaxy config file).  -->
      <param id="k8s_persistent_volume_claim_mount_path" from_environ="GALAXY_RUNNERS_K8S_PERSISTENT_VOLUME_CLAIM_MOUNT_PATH">/opt/galaxy_data</param>
      <param id="k8s_namespace" from_environ="GALAXY_RUNNERS_K8S_NAMESPACE">default</param>
      <param id="k8s_supplemental_group_id" from_environ="GALAXY_RUNNERS_K8S_SUPPLEMENTAL_GROUP_ID">0</param>
      <param id="k8s_fs_group_id" from_environ="GALAXY_RUNNERS_K8S_FS_GROUP_ID">0</param>
      <param id="k8s_pull_policy" from_environ="GALAXY_RUNNERS_K8S_PULL_POLICY">IfNotPresent</param>
      <!-- Allows pods to retry up to this number of times, before marking the Job as failed -->
      <param id="k8s_pod_retrials" from_environ="GALAXY_RUNNERS_K8S_POD_RETRIALS">1</param>
    </plugin>
  </plugins>
  <handlers default="handlers">
    <!--         HANDLERS -->
    <handler id="main" tags="handlers"/>
    <!-- HANDLERS  -->
    <!-- HANDLERS
    <handler id="handler0" tags="handlers"/>
    <handler id="handler1" tags="handlers"/>
         HANDLERS -->
  </handlers>
  <destinations default="local">
    <destination id="local" runner="local"/>
    <destination id="dynamic-k8s" runner="dynamic">
      <param id="type">python</param>
      <param id="function">k8s_wrapper</param>
      <param id="docker_enabled">true</param>
    </destination>
    <destination id="dynamic-k8s-tiny" runner="dynamic">
      <param id="type">python</param>
      <param id="function">k8s_wrapper_tiny</param>
      <resubmit condition="memory_limit_reached" destination="dynamic-k8s-small"/>
    </destination>
    <destination id="dynamic-k8s-small" runner="dynamic">
      <param id="type">python</param>
      <param id="function">k8s_wrapper_small</param>
      <resubmit condition="memory_limit_reached" destination="dynamic-k8s-medium"/>
    </destination>
    <destination id="dynamic-k8s-medium" runner="dynamic">
      <param id="type">python</param>
      <param id="function">k8s_wrapper_medium</param>
      <resubmit condition="memory_limit_reached" destination="dynamic-k8s-large"/>
    </destination>
    <destination id="dynamic-k8s-large" runner="dynamic">
      <param id="type">python</param>
      <param id="function">k8s_wrapper_large</param>
      <resubmit condition="memory_limit_reached" destination="dynamic-k8s-xlarge"/>
    </destination>
    <destination id="dynamic-k8s-xlarge" runner="dynamic">
      <param id="type">python</param>
      <param id="function">k8s_wrapper_xlarge</param>
    </destination>
  </destinations>
  <tools>
    <!-- Tools can be configured to use specific destinations or handlers,
         identified by either the "id" or "tags" attribute.  If assigned to
         a tag, a handler or destination that matches that tag will be
         chosen at random.  -->
    <!-- <tool id="pathway_enrichment" destination="dynamic-k8s-large" resources="all"/> -->

    
  </tools>
  <resources default="default">
    <!-- Group different parameters defined in job_resource_params_conf.xml
         together and assign these groups ids. Tool section below can map
         tools to different groups. This is experimental functionality!  -->
    <group id="cpu">requests_cpu,limits_cpu</group>
    <group id="memory">requests_memory,limits_memory</group>
    <group id="all">requests_cpu,limits_cpu,requests_memory,limits_memory</group>
  </resources>
</job_conf>

<!-- vim: set et sw=2 ts=2 -->
